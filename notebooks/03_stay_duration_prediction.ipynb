{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pickle\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in train and test datasets\n",
    "train_df = pd.read_csv('../data/train_origin.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# summing up duration-related columns to use as target variable \n",
    "train_df['Total_Duration'] = train_df['Administrative_Duration'] + train_df['Informational_Duration'] + train_df['ProductRelated_Duration']\n",
    "test_df['Total_Duration'] = test_df['Administrative_Duration'] + test_df['Informational_Duration'] + test_df['ProductRelated_Duration']                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing irrelevant columns (including columns that are considered as real-time information)\n",
    "train_df = train_df.drop(columns=['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated','ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'Revenue'])\n",
    "\n",
    "test_df = test_df.drop(columns=['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape before dropping duplicates:  (8631, 67)\n",
      "train_df shape after dropping duplicates:  (8520, 67)\n",
      "test_df shape before dropping duplicates:  (3699, 67)\n",
      "test_df shape after dropping duplicates:  (3673, 67)\n"
     ]
    }
   ],
   "source": [
    "# dropping duplicate values\n",
    "print('train_df shape before dropping duplicates: ', train_df.shape)\n",
    "train = train_df.drop_duplicates()\n",
    "print('train_df shape after dropping duplicates: ', train.shape)\n",
    "print('test_df shape before dropping duplicates: ', test_df.shape)\n",
    "test = test_df.drop_duplicates()\n",
    "print('test_df shape after dropping duplicates: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (8520, 66)\n",
      "y_train shape:  (8520,)\n",
      "X_test shape:  (3673, 66)\n",
      "y_test shape:  (3673,)\n"
     ]
    }
   ],
   "source": [
    "# separating the target variable\n",
    "X_train = train.iloc[:,:-1]\n",
    "y_train = train.iloc[:,-1]\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "X_test = test.iloc[:,:-1]\n",
    "y_test = test.iloc[:,-1]\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_ shape:  (6816, 66)\n",
      "y_train_ shape:  (6816,)\n",
      "X_val shape:  (1704, 66)\n",
      "y_val shape:  (1704,)\n"
     ]
    }
   ],
   "source": [
    "# obtaining validation set\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print('X_train_ shape: ', X_train_.shape)\n",
    "print('y_train_ shape: ', y_train_.shape)\n",
    "print('X_val shape: ', X_val.shape)\n",
    "print('y_val shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relu function to be used on the predictions\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define empty dataframe used to store metrics values for the different models\n",
    "score_df = pd.DataFrame()\n",
    "score_df.index = ['MAE', 'MSE', 'RMSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating an object of ExtraTreesRegressor class\n",
    "reg = ExtraTreesRegressor()\n",
    "reg.fit(X_train_,y_train_)\n",
    "\n",
    "# getting feature importance\n",
    "feat_importances = pd.Series(reg.feature_importances_, index=X_train_.columns)\n",
    "feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6.907292610251152\n",
      "2 6.903718895164162\n",
      "4 6.89318584435934\n",
      "5 6.76110599046892\n",
      "6 6.6805637017735515\n",
      "7 6.660886261678447\n"
     ]
    }
   ],
   "source": [
    "# obtaining the optimal columns to use for DecisionTreeRegressor\n",
    "min_score = np.inf\n",
    "best_num = 0\n",
    "for i in range(1, X_train_.shape[1]+1):    \n",
    "    impt_cols = list(feat_importances.nlargest(i).keys())\n",
    "    \n",
    "    # creating an object of DecisionTreeRegressor class\n",
    "    reg_decision_model = DecisionTreeRegressor()\n",
    "    reg_decision_model.fit(X_train_[impt_cols],y_train_)\n",
    "    \n",
    "    y_pred = reg_decision_model.predict(X_val[impt_cols])\n",
    "    \n",
    "    if mse(y_val, y_pred) < min_score:\n",
    "        min_score = mse(y_val, y_pred)\n",
    "        best_num = i\n",
    "        print(best_num, min_score)\n",
    "\n",
    "dt_impt_cols = list(feat_importances.nlargest(best_num).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Region_1',\n",
       " 'Weekend_False',\n",
       " 'Weekend_True',\n",
       " 'OperatingSystems_2',\n",
       " 'TrafficType_2',\n",
       " 'VisitorType_Returning_Visitor',\n",
       " 'Browser_4']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_impt_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of DecisionTreeRegressor class\n",
    "reg_decision_model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for grid search\n",
    "parameters={\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "           \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "           \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "           \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of GridSearchCV class for hyperparameter tuning\n",
    "dt_tuning_model = GridSearchCV(reg_decision_model,param_grid=parameters,scoring='neg_mean_squared_error',cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 21s\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "%%time\n",
    "%%capture\n",
    "dt_tuning_model.fit(X_train_[dt_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': 50,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_weight_fraction_leaf': 0.1,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters \n",
    "dt_tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.481933651598598"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tuning_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of DecisionTreeRegressor class with optimal parameters\n",
    "dt_tuned_hyper_model= DecisionTreeRegressor(max_depth=9,max_features='log2',max_leaf_nodes=50,min_samples_leaf=3,min_weight_fraction_leaf=0.1,splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=9, max_features='log2', max_leaf_nodes=50,\n",
       "                      min_samples_leaf=3, min_weight_fraction_leaf=0.1,\n",
       "                      splitter='random')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training set\n",
    "dt_tuned_hyper_model.fit(X_train_[dt_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.317963049303732\n",
      "MSE: 6.889988044635591\n",
      "RMSE: 2.624878672364799\n"
     ]
    }
   ],
   "source": [
    "# testing the tuned model with the validation set\n",
    "dt_tuned_pred_val = relu(dt_tuned_hyper_model.predict(X_val[dt_impt_cols]))\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_val,dt_tuned_pred_val))\n",
    "print('MSE:', metrics.mean_squared_error(y_val, dt_tuned_pred_val))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, dt_tuned_pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving validation results to score_df\n",
    "score_df['DecisionTreeRegressor'] = np.array([metrics.mean_absolute_error(y_val,dt_tuned_pred_val),\n",
    "                                              metrics.mean_squared_error(y_val, dt_tuned_pred_val),\n",
    "                                              np.sqrt(metrics.mean_squared_error(y_val, dt_tuned_pred_val))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6.907292610251152\n",
      "2 6.904127029190034\n",
      "4 6.902135240716614\n",
      "5 6.7845181526576\n",
      "6 6.746002907505769\n",
      "7 6.739994118221701\n",
      "8 6.734437354680547\n",
      "9 6.710122424583445\n",
      "10 6.707545330053155\n",
      "11 6.706920841273918\n",
      "13 6.6966049303958375\n",
      "16 6.694812539252705\n"
     ]
    }
   ],
   "source": [
    "# obtaining the optimal columns to use for LinearRegression\n",
    "min_score = np.inf\n",
    "best_num = 0\n",
    "for i in range(1, X_train_.shape[1]+1):    \n",
    "    impt_cols = list(feat_importances.nlargest(i).keys())\n",
    "    \n",
    "    # creating an object of LinearRegression class\n",
    "    LR = LinearRegression()\n",
    "    LR.fit(X_train_[impt_cols],y_train_)\n",
    "    \n",
    "    y_pred = LR.predict(X_val[impt_cols])\n",
    "    \n",
    "    if mse(y_val, y_pred) < min_score:\n",
    "        min_score = mse(y_val, y_pred)\n",
    "        best_num = i\n",
    "        print(best_num, min_score)\n",
    "\n",
    "lr_impt_cols = list(feat_importances.nlargest(best_num).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Region_1',\n",
       " 'Weekend_False',\n",
       " 'Weekend_True',\n",
       " 'OperatingSystems_2',\n",
       " 'TrafficType_2',\n",
       " 'VisitorType_Returning_Visitor',\n",
       " 'Browser_4',\n",
       " 'Region_3',\n",
       " 'Month_Nov',\n",
       " 'OperatingSystems_1',\n",
       " 'OperatingSystems_4',\n",
       " 'Region_2',\n",
       " 'Browser_2',\n",
       " 'Month_Jul',\n",
       " 'OperatingSystems_3',\n",
       " 'SpecialDay']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_impt_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an object of LinearRegression class\n",
    "LR = LinearRegression()\n",
    "\n",
    "# fitting model to training set\n",
    "LR.fit(X_train_[lr_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.2819118030378476\n",
      "MSE: 6.694515604648001\n",
      "RMSE: 2.587376200835124\n"
     ]
    }
   ],
   "source": [
    "# testing the model with the validation set\n",
    "y_prediction_val = relu(LR.predict(X_val[lr_impt_cols]))\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_val,y_prediction_val))\n",
    "print('MSE:', metrics.mean_squared_error(y_val, y_prediction_val))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, y_prediction_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving validation results to score_df\n",
    "score_df['LinearRegression'] = np.array([metrics.mean_absolute_error(y_val,y_prediction_val),\n",
    "                                              metrics.mean_squared_error(y_val, y_prediction_val),\n",
    "                                              np.sqrt(metrics.mean_squared_error(y_val, y_prediction_val))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6.9072927240079816\n",
      "2 6.903719066775359\n",
      "4 6.893185709704401\n",
      "5 6.761647061614968\n",
      "6 6.701824874814142\n",
      "7 6.683301709122467\n",
      "9 6.668712480853729\n",
      "10 6.662112833186758\n",
      "13 6.654150185445455\n",
      "15 6.651024452197535\n",
      "16 6.649185540837635\n",
      "17 6.6472853441644855\n",
      "40 6.642947361615867\n"
     ]
    }
   ],
   "source": [
    "# obtaining the optimal columns to use for GradientBoostingRegressor\n",
    "min_score = np.inf\n",
    "best_num = 0\n",
    "for i in range(1, X_train_.shape[1]+1):    \n",
    "    impt_cols = list(feat_importances.nlargest(i).keys())\n",
    "    \n",
    "    # creating an object of GradientBoostingRegressor class\n",
    "    reg_decision_model = GradientBoostingRegressor()\n",
    "    reg_decision_model.fit(X_train_[impt_cols],y_train_)\n",
    "    \n",
    "    y_pred = reg_decision_model.predict(X_val[impt_cols])\n",
    "    \n",
    "    if mse(y_val, y_pred) < min_score:\n",
    "        min_score = mse(y_val, y_pred)\n",
    "        best_num = i\n",
    "        print(best_num, min_score)\n",
    "\n",
    "gbr_impt_cols = list(feat_importances.nlargest(best_num).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Region_1',\n",
       " 'Weekend_False',\n",
       " 'Weekend_True',\n",
       " 'OperatingSystems_2',\n",
       " 'TrafficType_2',\n",
       " 'VisitorType_Returning_Visitor',\n",
       " 'Browser_4',\n",
       " 'Region_3',\n",
       " 'Month_Nov',\n",
       " 'OperatingSystems_1',\n",
       " 'OperatingSystems_4',\n",
       " 'Region_2',\n",
       " 'Browser_2',\n",
       " 'Month_Jul',\n",
       " 'OperatingSystems_3',\n",
       " 'SpecialDay',\n",
       " 'Region_4',\n",
       " 'TrafficType_1',\n",
       " 'TrafficType_13',\n",
       " 'Browser_1',\n",
       " 'TrafficType_14',\n",
       " 'Region_6',\n",
       " 'Month_Dec',\n",
       " 'Region_7',\n",
       " 'Month_Sep',\n",
       " 'Region_9',\n",
       " 'TrafficType_3',\n",
       " 'Region_5',\n",
       " 'Month_Oct',\n",
       " 'Region_8',\n",
       " 'Browser_10',\n",
       " 'Browser_6',\n",
       " 'Browser_5',\n",
       " 'TrafficType_6',\n",
       " 'Month_May',\n",
       " 'VisitorType_New_Visitor',\n",
       " 'Month_June',\n",
       " 'TrafficType_10',\n",
       " 'Month_Mar',\n",
       " 'TrafficType_4']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_impt_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of GradientBoostingRegressor class\n",
    "reg_gradient_model = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for grid search\n",
    "params = {\"max_depth\" : [1,3,5,7,9,11,12],\n",
    "          \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "          \"learning_rate\": [0.001,0.01,0.05,0.1],\n",
    "          \"loss\": ['quantile'],\n",
    "          \"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of GridSearchCV class for hyperparameter tuning\n",
    "gbr_tuning_model = GridSearchCV(reg_gradient_model,param_grid=params,scoring='neg_mean_squared_error',cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 55min 13s\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "%%time\n",
    "%%capture\n",
    "gbr_tuning_model.fit(X_train_[gbr_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.7,\n",
       " 'learning_rate': 0.05,\n",
       " 'loss': 'quantile',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters\n",
    "gbr_tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.351408481062597"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_tuning_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of GradientBoostingRegressor class with optimal parameters\n",
    "gbr_tuned_hyper_model = GradientBoostingRegressor(alpha=0.7,max_features='sqrt',learning_rate=0.05,loss='quantile',max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.7, learning_rate=0.05, loss='quantile',\n",
       "                          max_depth=5, max_features='sqrt')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training set\n",
    "gbr_tuned_hyper_model.fit(X_train_[gbr_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.2741571503135958\n",
      "MSE: 6.637096077176464\n",
      "RMSE: 2.576256213418313\n"
     ]
    }
   ],
   "source": [
    "# testing the tuned model with the validation set\n",
    "gbr_tuned_pred_val = relu(gbr_tuned_hyper_model.predict(X_val[gbr_impt_cols]))\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_val,gbr_tuned_pred_val))\n",
    "print('MSE:', metrics.mean_squared_error(y_val, gbr_tuned_pred_val))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, gbr_tuned_pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving validation results to score_df\n",
    "score_df['GradientBoostingRegressor'] = np.array([metrics.mean_absolute_error(y_val,gbr_tuned_pred_val),\n",
    "                                              metrics.mean_squared_error(y_val, gbr_tuned_pred_val),\n",
    "                                              np.sqrt(metrics.mean_squared_error(y_val, gbr_tuned_pred_val))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.317963</td>\n",
       "      <td>1.281912</td>\n",
       "      <td>1.274157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>6.889988</td>\n",
       "      <td>6.694516</td>\n",
       "      <td>6.637096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>2.624879</td>\n",
       "      <td>2.587376</td>\n",
       "      <td>2.576256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DecisionTreeRegressor  LinearRegression  GradientBoostingRegressor\n",
       "MAE                1.317963          1.281912                   1.274157\n",
       "MSE                6.889988          6.694516                   6.637096\n",
       "RMSE               2.624879          2.587376                   2.576256"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.2561356867105453\n",
      "MSE: 4.337133894901668\n",
      "RMSE: 2.0825786647571487\n"
     ]
    }
   ],
   "source": [
    "final_model = GradientBoostingRegressor(alpha=0.7,max_features='sqrt',learning_rate=0.05,loss='quantile',max_depth=5)\n",
    "# fitting the model to the full train dataset\n",
    "final_model.fit(X_train[gbr_impt_cols],y_train)\n",
    "final_pred = relu(final_model.predict(X_test[gbr_impt_cols]))\n",
    "    \n",
    "print('MAE:', metrics.mean_absolute_error(y_test,final_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, final_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, final_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving columns used in the model\n",
    "col_dict = {'columns': gbr_impt_cols}\n",
    "with open('../trained_models/stay_duration_pred.json', 'w') as f:\n",
    "    json.dump(col_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = '../trained_models/stay_duration_pred.sav'\n",
    "pickle.dump(final_model, open(filename, 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "55bda7f6a3882832ddb0977e6913a31d0b47758aa2ccff05510fd18f5a854727"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}