{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"Administrative\", \"Administrative Duration\", \"Informational\", \"Informational Duration\", \"Product Related\" and \"Product Related Duration\":\n",
    "    - represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. \n",
    "    - values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an \n",
    "        action, e.g. moving from one page to another.\n",
    "\"Bounce Rate\", \"Exit Rate\" and \"Page Value\":\n",
    "    - features represent the metrics measured by \"Google Analytics\" for each page in the e-commerce site.\n",
    "    - \"Bounce Rate\" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (\"bounce\") \n",
    "        without triggering any other requests to the analytics server during that session. \n",
    "    - \"Exit Rate\" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session.\n",
    "    - \"Page Value\" feature represents the average value for a web page that a user visited before completing an e-commerce transaction.\n",
    "    - \"Special Day\" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which\n",
    "        the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of\n",
    "        e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value\n",
    "        between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1\n",
    "        on February 8.\n",
    "The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating \n",
    "whether the date of the visit is weekend, and month of the year.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in train and test datasets\n",
    "train_df = pd.read_csv('data/train_origin.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# summing up duration-related columns to use as target variable \n",
    "train_df['Total_Duration'] = train_df['Administrative_Duration'] + train_df['Informational_Duration'] + train_df['ProductRelated_Duration']\n",
    "test_df['Total_Duration'] = test_df['Administrative_Duration'] + test_df['Informational_Duration'] + test_df['ProductRelated_Duration']                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing irrelevant columns (including columns that are considered as real-time information)\n",
    "train_df = train_df.drop(columns=['Unnamed: 0', 'Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated',\n",
    "                                  'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'Revenue'])\n",
    "test_df = test_df.drop(columns=['Unnamed: 0', 'Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated',\n",
    "                                  'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape before dropping duplicates:  (8631, 67)\n",
      "train_df shape after dropping duplicates:  (8520, 67)\n",
      "test_df shape before dropping duplicates:  (3699, 67)\n",
      "test_df shape after dropping duplicates:  (3673, 67)\n"
     ]
    }
   ],
   "source": [
    "# dropping duplicate values\n",
    "print('train_df shape before dropping duplicates: ', train_df.shape)\n",
    "train = train_df.drop_duplicates()\n",
    "print('train_df shape after dropping duplicates: ', train.shape)\n",
    "print('test_df shape before dropping duplicates: ', test_df.shape)\n",
    "test = test_df.drop_duplicates()\n",
    "print('test_df shape after dropping duplicates: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (8520, 66)\n",
      "y_train shape:  (8520,)\n",
      "X_test shape:  (3673, 66)\n",
      "y_test shape:  (3673,)\n"
     ]
    }
   ],
   "source": [
    "# separating the target variable\n",
    "X_train = train.iloc[:,:-1]\n",
    "y_train = train.iloc[:,-1]\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "X_test = test.iloc[:,:-1]\n",
    "y_test = test.iloc[:,-1]\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_ shape:  (6816, 66)\n",
      "y_train_ shape:  (6816,)\n",
      "X_val shape:  (1704, 66)\n",
      "y_val shape:  (1704,)\n"
     ]
    }
   ],
   "source": [
    "# obtaining validation set\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print('X_train_ shape: ', X_train_.shape)\n",
    "print('y_train_ shape: ', y_train_.shape)\n",
    "print('X_val shape: ', X_val.shape)\n",
    "print('y_val shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relu function to be used on the predictions\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define empty dataframe used to store metrics values for the different models\n",
    "score_df = pd.DataFrame()\n",
    "score_df.index = ['MAE', 'MSE', 'RMSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating an object of ExtraTreesRegressor class\n",
    "reg = ExtraTreesRegressor()\n",
    "reg.fit(X_train_,y_train_)\n",
    "\n",
    "# getting feature importance\n",
    "feat_importances = pd.Series(reg.feature_importances_, index=X_train_.columns)\n",
    "feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6.907292610251152\n",
      "2 6.903718895164162\n",
      "4 6.89318584435934\n",
      "5 6.76110599046892\n",
      "6 6.6805637017735515\n",
      "7 6.660886261678447\n"
     ]
    }
   ],
   "source": [
    "# obtaining the optimal columns to use for DecisionTreeRegressor\n",
    "min_score = np.inf\n",
    "best_num = 0\n",
    "for i in range(1, X_train_.shape[1]+1):    \n",
    "    impt_cols = list(feat_importances.nlargest(i).keys())\n",
    "    \n",
    "    # creating an object of DecisionTreeRegressor class\n",
    "    reg_decision_model = DecisionTreeRegressor()\n",
    "    reg_decision_model.fit(X_train_[impt_cols],y_train_)\n",
    "    \n",
    "    y_pred = reg_decision_model.predict(X_val[impt_cols])\n",
    "    \n",
    "    if mse(y_val, y_pred) < min_score:\n",
    "        min_score = mse(y_val, y_pred)\n",
    "        best_num = i\n",
    "        print(best_num, min_score)\n",
    "\n",
    "dt_impt_cols = list(feat_importances.nlargest(best_num).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Region_1',\n",
       " 'Weekend_False',\n",
       " 'Weekend_True',\n",
       " 'OperatingSystems_2',\n",
       " 'TrafficType_2',\n",
       " 'VisitorType_Returning_Visitor',\n",
       " 'Browser_4']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_impt_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of DecisionTreeRegressor class\n",
    "reg_decision_model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for grid search\n",
    "parameters={\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "           \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "           \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "           \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of GridSearchCV class for hyperparameter tuning\n",
    "dt_tuning_model = GridSearchCV(reg_decision_model,param_grid=parameters,scoring='neg_mean_squared_error',cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 21s\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "%%time\n",
    "%%capture\n",
    "dt_tuning_model.fit(X_train_[dt_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': 50,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_weight_fraction_leaf': 0.1,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters \n",
    "dt_tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.481933651598598"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tuning_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of DecisionTreeRegressor class with optimal parameters\n",
    "dt_tuned_hyper_model= DecisionTreeRegressor(max_depth=9,max_features='log2',max_leaf_nodes=50,min_samples_leaf=3,min_weight_fraction_leaf=0.1,splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=9, max_features='log2', max_leaf_nodes=50,\n",
       "                      min_samples_leaf=3, min_weight_fraction_leaf=0.1,\n",
       "                      splitter='random')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training set\n",
    "dt_tuned_hyper_model.fit(X_train_[dt_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.317963049303732\n",
      "MSE: 6.889988044635591\n",
      "RMSE: 2.624878672364799\n"
     ]
    }
   ],
   "source": [
    "# testing the tuned model with the validation set\n",
    "dt_tuned_pred_val = relu(dt_tuned_hyper_model.predict(X_val[dt_impt_cols]))\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_val,dt_tuned_pred_val))\n",
    "print('MSE:', metrics.mean_squared_error(y_val, dt_tuned_pred_val))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, dt_tuned_pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving validation results to score_df\n",
    "score_df['DecisionTreeRegressor'] = np.array([metrics.mean_absolute_error(y_val,dt_tuned_pred_val),\n",
    "                                              metrics.mean_squared_error(y_val, dt_tuned_pred_val),\n",
    "                                              np.sqrt(metrics.mean_squared_error(y_val, dt_tuned_pred_val))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6.907292610251152\n",
      "2 6.904127029190034\n",
      "4 6.902135240716614\n",
      "5 6.7845181526576\n",
      "6 6.746002907505769\n",
      "7 6.739994118221701\n",
      "8 6.734437354680547\n",
      "9 6.710122424583445\n",
      "10 6.707545330053155\n",
      "11 6.706920841273918\n",
      "13 6.6966049303958375\n",
      "16 6.694812539252705\n"
     ]
    }
   ],
   "source": [
    "# obtaining the optimal columns to use for LinearRegression\n",
    "min_score = np.inf\n",
    "best_num = 0\n",
    "for i in range(1, X_train_.shape[1]+1):    \n",
    "    impt_cols = list(feat_importances.nlargest(i).keys())\n",
    "    \n",
    "    # creating an object of LinearRegression class\n",
    "    LR = LinearRegression()\n",
    "    LR.fit(X_train_[impt_cols],y_train_)\n",
    "    \n",
    "    y_pred = LR.predict(X_val[impt_cols])\n",
    "    \n",
    "    if mse(y_val, y_pred) < min_score:\n",
    "        min_score = mse(y_val, y_pred)\n",
    "        best_num = i\n",
    "        print(best_num, min_score)\n",
    "\n",
    "lr_impt_cols = list(feat_importances.nlargest(best_num).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Region_1',\n",
       " 'Weekend_False',\n",
       " 'Weekend_True',\n",
       " 'OperatingSystems_2',\n",
       " 'TrafficType_2',\n",
       " 'VisitorType_Returning_Visitor',\n",
       " 'Browser_4',\n",
       " 'Region_3',\n",
       " 'Month_Nov',\n",
       " 'OperatingSystems_1',\n",
       " 'OperatingSystems_4',\n",
       " 'Region_2',\n",
       " 'Browser_2',\n",
       " 'Month_Jul',\n",
       " 'OperatingSystems_3',\n",
       " 'SpecialDay']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_impt_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an object of LinearRegression class\n",
    "LR = LinearRegression()\n",
    "\n",
    "# fitting model to training set\n",
    "LR.fit(X_train_[lr_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.2819118030378476\n",
      "MSE: 6.694515604648001\n",
      "RMSE: 2.587376200835124\n"
     ]
    }
   ],
   "source": [
    "# testing the model with the validation set\n",
    "y_prediction_val = relu(LR.predict(X_val[lr_impt_cols]))\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_val,y_prediction_val))\n",
    "print('MSE:', metrics.mean_squared_error(y_val, y_prediction_val))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, y_prediction_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving validation results to score_df\n",
    "score_df['LinearRegression'] = np.array([metrics.mean_absolute_error(y_val,y_prediction_val),\n",
    "                                              metrics.mean_squared_error(y_val, y_prediction_val),\n",
    "                                              np.sqrt(metrics.mean_squared_error(y_val, y_prediction_val))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6.9072927240079816\n",
      "2 6.903719066775359\n",
      "4 6.893185709704401\n",
      "5 6.761647061614968\n",
      "6 6.701824874814142\n",
      "7 6.683301709122467\n",
      "9 6.668712480853729\n",
      "10 6.662112833186758\n",
      "13 6.654150185445455\n",
      "15 6.651024452197535\n",
      "16 6.649185540837635\n",
      "17 6.6472853441644855\n",
      "40 6.642947361615867\n"
     ]
    }
   ],
   "source": [
    "# obtaining the optimal columns to use for GradientBoostingRegressor\n",
    "min_score = np.inf\n",
    "best_num = 0\n",
    "for i in range(1, X_train_.shape[1]+1):    \n",
    "    impt_cols = list(feat_importances.nlargest(i).keys())\n",
    "    \n",
    "    # creating an object of GradientBoostingRegressor class\n",
    "    reg_decision_model = GradientBoostingRegressor()\n",
    "    reg_decision_model.fit(X_train_[impt_cols],y_train_)\n",
    "    \n",
    "    y_pred = reg_decision_model.predict(X_val[impt_cols])\n",
    "    \n",
    "    if mse(y_val, y_pred) < min_score:\n",
    "        min_score = mse(y_val, y_pred)\n",
    "        best_num = i\n",
    "        print(best_num, min_score)\n",
    "\n",
    "gbr_impt_cols = list(feat_importances.nlargest(best_num).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Region_1',\n",
       " 'Weekend_False',\n",
       " 'Weekend_True',\n",
       " 'OperatingSystems_2',\n",
       " 'TrafficType_2',\n",
       " 'VisitorType_Returning_Visitor',\n",
       " 'Browser_4',\n",
       " 'Region_3',\n",
       " 'Month_Nov',\n",
       " 'OperatingSystems_1',\n",
       " 'OperatingSystems_4',\n",
       " 'Region_2',\n",
       " 'Browser_2',\n",
       " 'Month_Jul',\n",
       " 'OperatingSystems_3',\n",
       " 'SpecialDay',\n",
       " 'Region_4',\n",
       " 'TrafficType_1',\n",
       " 'TrafficType_13',\n",
       " 'Browser_1',\n",
       " 'TrafficType_14',\n",
       " 'Region_6',\n",
       " 'Month_Dec',\n",
       " 'Region_7',\n",
       " 'Month_Sep',\n",
       " 'Region_9',\n",
       " 'TrafficType_3',\n",
       " 'Region_5',\n",
       " 'Month_Oct',\n",
       " 'Region_8',\n",
       " 'Browser_10',\n",
       " 'Browser_6',\n",
       " 'Browser_5',\n",
       " 'TrafficType_6',\n",
       " 'Month_May',\n",
       " 'VisitorType_New_Visitor',\n",
       " 'Month_June',\n",
       " 'TrafficType_10',\n",
       " 'Month_Mar',\n",
       " 'TrafficType_4']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_impt_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of GradientBoostingRegressor class\n",
    "reg_gradient_model = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for grid search\n",
    "params = {\"max_depth\" : [1,3,5,7,9,11,12],\n",
    "          \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "          \"learning_rate\": [0.001,0.01,0.05,0.1],\n",
    "          \"loss\": ['quantile'],\n",
    "          \"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of GridSearchCV class for hyperparameter tuning\n",
    "gbr_tuning_model = GridSearchCV(reg_gradient_model,param_grid=params,scoring='neg_mean_squared_error',cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 55min 13s\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "%%time\n",
    "%%capture\n",
    "gbr_tuning_model.fit(X_train_[gbr_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.7,\n",
       " 'learning_rate': 0.05,\n",
       " 'loss': 'quantile',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters\n",
    "gbr_tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.351408481062597"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_tuning_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of GradientBoostingRegressor class with optimal parameters\n",
    "gbr_tuned_hyper_model = GradientBoostingRegressor(alpha=0.7,max_features='sqrt',learning_rate=0.05,loss='quantile',max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.7, learning_rate=0.05, loss='quantile',\n",
       "                          max_depth=5, max_features='sqrt')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to training set\n",
    "gbr_tuned_hyper_model.fit(X_train_[gbr_impt_cols],y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.2741571503135958\n",
      "MSE: 6.637096077176464\n",
      "RMSE: 2.576256213418313\n"
     ]
    }
   ],
   "source": [
    "# testing the tuned model with the validation set\n",
    "gbr_tuned_pred_val = relu(gbr_tuned_hyper_model.predict(X_val[gbr_impt_cols]))\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_val,gbr_tuned_pred_val))\n",
    "print('MSE:', metrics.mean_squared_error(y_val, gbr_tuned_pred_val))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, gbr_tuned_pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving validation results to score_df\n",
    "score_df['GradientBoostingRegressor'] = np.array([metrics.mean_absolute_error(y_val,gbr_tuned_pred_val),\n",
    "                                              metrics.mean_squared_error(y_val, gbr_tuned_pred_val),\n",
    "                                              np.sqrt(metrics.mean_squared_error(y_val, gbr_tuned_pred_val))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.317963</td>\n",
       "      <td>1.281912</td>\n",
       "      <td>1.274157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>6.889988</td>\n",
       "      <td>6.694516</td>\n",
       "      <td>6.637096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>2.624879</td>\n",
       "      <td>2.587376</td>\n",
       "      <td>2.576256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DecisionTreeRegressor  LinearRegression  GradientBoostingRegressor\n",
       "MAE                1.317963          1.281912                   1.274157\n",
       "MSE                6.889988          6.694516                   6.637096\n",
       "RMSE               2.624879          2.587376                   2.576256"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.2561356867105453\n",
      "MSE: 4.337133894901668\n",
      "RMSE: 2.0825786647571487\n"
     ]
    }
   ],
   "source": [
    "final_model = GradientBoostingRegressor(alpha=0.7,max_features='sqrt',learning_rate=0.05,loss='quantile',max_depth=5)\n",
    "# fitting the model to the full train dataset\n",
    "final_model.fit(X_train[gbr_impt_cols],y_train)\n",
    "final_pred = relu(final_model.predict(X_test[gbr_impt_cols]))\n",
    "    \n",
    "print('MAE:', metrics.mean_absolute_error(y_test,final_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, final_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, final_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving columns used in the model\n",
    "col_dict = {'columns': gbr_impt_cols}\n",
    "with open('trained_models/stay_duration_pred.json', 'w') as f:\n",
    "    json.dump(col_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'trained_models/stay_duration_pred.sav'\n",
    "pickle.dump(final_model, open(filename, 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
